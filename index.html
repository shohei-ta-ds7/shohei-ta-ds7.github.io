<html>
    <head>
      <meta charset="UTF-8">
      <title>Shohei Tanaka</title>
      <link rel="stylesheet" type="text/css" href="style.css">
      <!-- <link rel="shortcut icon" type="image/vnd.microsoft.icon" href="./favicons/favicon.ico">
      <link rel="icon" type="image/vnd.microsoft.icon" href="./favicons/favicon.ico">
      <link rel="apple-touch-icon" sizes="57x57" href="./favicons/apple-touch-icon-57x57.png">
      <link rel="apple-touch-icon" sizes="60x60" href="./favicons/apple-touch-icon-60x60.png">
      <link rel="apple-touch-icon" sizes="72x72" href="./favicons/apple-touch-icon-72x72.png">
      <link rel="apple-touch-icon" sizes="76x76" href="./favicons/apple-touch-icon-76x76.png">
      <link rel="apple-touch-icon" sizes="114x114" href="./favicons/apple-touch-icon-114x114.png">
      <link rel="apple-touch-icon" sizes="120x120" href="./favicons/apple-touch-icon-120x120.png">
      <link rel="apple-touch-icon" sizes="144x144" href="./favicons/apple-touch-icon-144x144.png">
      <link rel="apple-touch-icon" sizes="152x152" href="./favicons/apple-touch-icon-152x152.png">
      <link rel="apple-touch-icon" sizes="180x180" href="./favicons/apple-touch-icon-180x180.png">
      <link rel="icon" type="image/png" sizes="192x192" href="./favicons/android-chrome-192x192.png">
      <link rel="icon" type="image/png" sizes="48x48" href="./favicons/favicon-48x48.png">
      <link rel="icon" type="image/png" sizes="96x96" href="./favicons/favicon-96x96.png">
      <link rel="icon" type="image/png" sizes="96x96" href="./favicons/favicon-160x160.png">
      <link rel="icon" type="image/png" sizes="96x96" href="./favicons/favicon-196x196.png">
      <link rel="icon" type="image/png" sizes="16x16" href="./favicons/favicon-16x16.png">
      <link rel="icon" type="image/png" sizes="32x32" href="./favicons/favicon-32x32.png">
      <link rel="manifest" href="./favicons/manifest.json"> -->
      <!-- <meta name="msapplication-TileColor" content="#2d88ef">
      <meta name="msapplication-TileImage" content="./favicons/mstile-144x144.png"> -->
    </head>
    <body>
      <!-- <div class="Header">
        <label style="color: #FFFFFF; margin-top: 10px; font-size: 40px;">Shohei TANAKA</label>
      </div> -->

      <br>
      <br>

      <div class="Body">
        <fieldset class="Body">
          <h1 style="padding: 5px;">
            <span class="Body">
              Shohei Tanaka (田中 翔平)
            </span>
          </h1>
          <img src="profile.png" class="Work">
          <p class="Body">
            Project Researcher @ OMRON SINIC X, Japan<br>
            E-mail: shohei.tanaka[at]sinicx.com
          </p>

          <h2 class="Body">
            <span class="Body">
              Profile
            </span>
          </h2>
          <p class="Body">
            I am a project researcher at OMRON SINIC X.
            My research interest lies in AI for science, natural language processing, computer vision, and robotics.
            I received my Doctor of Engineering from Nara Institute of Science and Technology in 2023. 2021-2023, Junior Research Associate at Guardian Robot Project, RIKEN.
            2019, Best Paper Award, The 1st Workshop NLP for Conversational AI ACL 2019 Workshop (ConvAI).
          </p>

          <h2 class="Body">
            <span class="Body">
              Education
            </span>
          </h2>
          <ul class="None">
            <li>
              <b>Doctor of Engineering, Nara Institute of Science and Technology, Japan, 2023</b><br>
              <b>Dissertation:</b> <a href="https://library.naist.jp/opac/en/book/106975">Reflective Response of Dialogue System Focusing on User's Event</a></a><br>
              <b>Supervisor:</b> <a href="https://ahcweb01.naist.jp/Prof.Nakamura/index_e.html">Prof. Satoshi Nakamura</a>
            </li>
            <li>
              <b>Master of Engineering, Nara Institute of Science and Technology, Japan, 2020</b><br>
              <b>Thesis:</b> Conversational Response Re-ranking Based on Coherency of Sequential Events<br>
              <b>Supervisor:</b> <a href="https://ahcweb01.naist.jp/Prof.Nakamura/index_e.html">Prof. Satoshi Nakamura</a>
            </li>
            <li>
              <b>Bachelor of Engineering, Nagoya Institute of Technology, Japan, 2018</b><br>
              <b>Thesis:</b> A Design Methodology of Real-World Universal Voice Interface and its Model Case: "Easy Talk Suhama-Shoten"<br>
              <b>Supervisor:</b> <a href="https://www.slp.nitech.ac.jp/en/members/ri/">Prof. Akinobu Lee</a>
            </li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Work Experience
            </span>
          </h2>
          <ul class="None">
            <li>
              <b>Researcher</b><br>
              <ul>
                <li>Project Researcher, OMRON SINIC X, Japan, April 2023 -- Present</li>
              </ul>
            </li>

            <li>
              <b>Research Assistant</b><br>
              <ul>
                <li>Guardian Robot Project (GRP), RIKEN, Japan, April 2021 -- March 2023</li>
                <li>Center for Advanced Intelligence Project (AIP), RIKEN, Japan, July 2020 -- March 2021</li>
                <li>Nara Institute of Science and Technology, Japan, June 2019 -- March 2023</li>
                <li>PRESTO, Japan Science and Technology Agency, Japan, April 2019 -- June 2020</li>
                <li>National Institute of Information and Communications Technology (NICT), Japan, November 2018 -- March 2019</li>
              </ul>
            </li>
            <!-- <li>
              <b>Others</b><br>
              <ul>
              </ul>
            </li> -->
            <li>
              <b>Internships</b><br>
              <ul>
                <li>rinna Co., Ltd., Japan, September 2022 -- November 2022</li>
                <li>Signals & Interactive Systems Laboratory of Prof. Giuseppe Riccardi, University of Trento, Italy, April 2022 -- July 2022</li>
                <li>Fixstars Inc., Japan, February 2018 -- March 2018</li>
                <li>Nissan Motor Co., Ltd., Japan, August 2016 -- September 2016</li>
              </ul>
            </li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Publications
            </span>
          </h2>
          <ul class="None">
            <li>
              <b>Referred Journal Papers</b><br>
              <ul>
                <li>
                  Edgar Anarossi, Yuhwan Kwon, Hirotaka Tahara, <u>Shohei Tanaka</u>, Keisuke Shirai, Masashi Hamaya, Cristian C Beltran-Hernandez, Atsushi Hashimoto, Takamitsu Matsubara.<br>
                  ``<a href="https://ieeexplore.ieee.org/document/11079980">KeyMPs: One-Shot Vision-Language Guided Motion Generation by Sequencing DMPs for Occlusion-Rich Tasks"</a><br>
                  IEEE Access, pp. 125420-125441, Volume 13, July 2025<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Konosuke Yamasaki, Akishige Yuguchi, Seiya Kawano, Satoshi Nakamura, Koichiro Yoshino.<br>
                  ``<a href="https://ieeexplore.ieee.org/document/10381769">Do As I Demand, Not As I Say: A Dataset for Developing Reflective Life-Support Robot"</a><br>
                  IEEE Access, pp. 11774-11784, Volume 12, January 2024<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://www.sciencedirect.com/science/article/pii/S0885230822000869">Reflective Action Selection Based on Positive-Unlabeled Learning and Causality Detection Model"</a><br>
                  Computer Speech & Language (CSL), Volume 78, March 2023<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://www.jstage.jst.go.jp/article/jnlp/28/1/28_26/_article/-char/ja/">Relationships Between Coherency of Sequential Events and Dialogue Continuity on Conversational Response"</a><br>
                  Transaction of Natural Language Processing (TNLP), pp. 26-59, Number 1, Volume 28, March 2021, In Japanese<br>
                </li>
              </ul>
            </li>

            <li>
              <b>Referred Conference Papers</b><br>
              <ul>
                <li>
                  Konosuke Yamasaki, <u>Shohei Tanaka</u>, Akishige Yuguchi, Seiya Kawano, Koichiro Yoshino.<br>
                  ``<a href="">Multi-step or Direct: A Proactive Life-support System Based on Commonsense Reasoning</a>"<br>
                  The 26th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pp. TBD, Avignon, France, August 2025<br>
                </li>
                <li>
                  Risa Shinoda, Kuniaki Saito, <u>Shohei Tanaka</u>, Tosho Hirasawa, Yoshitaka Ushiku.<br>
                  ``<a href="https://arxiv.org/abs/2412.17606">SBS Figures: Pre-training Figure QA from Stage-by-Stage Synthesized Images</a>"<br>
                  AAAI-25 Workshop on Document Understanding and Intelligence, Philadelphia, Pennsylvania, USA, March 2025<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Hao Wang, Yoshitaka Ushiku.<br>
                  ``<a href="https://arxiv.org/abs/2407.19787">SciPostLayout: A Dataset for Layout Analysis and Layout Generation of Scientific Posters</a>"<br>
                  The 35th British Machine Vision Conference (BMVC), Glasgow, UK, November 2024<br>
                </li>
                <li>
                  Keisuke Shirai, Cristian C. Beltran-Hernandez, Masashi Hamaya, Atsushi Hashimoto, <u>Shohei Tanaka</u>, Kento Kawaharazuka, Kazutoshi Tanaka, Yoshitaka Ushiku, Shinsuke Mori.<br>
                  ``<a href="https://arxiv.org/abs/2311.00967">Vision-Language Interpreter for Robot Task Planning</a>"<br>
                  2024 IEEE International Conference on Robotics and Automation (ICRA), May 2024<br>
                </li>
                <li>
                  Seyed Mahed Mousavi, <u>Shohei Tanaka</u>, Gabriel Roccabruna, Koichiro Yoshino, Satoshi Nakamura, Giuseppe Riccardi.<br>
                  ``<a href="https://aclanthology.org/2023.wnu-1.1/">What’s New? Identifying the Unfolding of New Events in a Narrative</a>"<br>
                  The 5th Workshop on Narrative Understanding ACL 2023 Workshop, pp. 1-10, Toronto, Canada, July 2023<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  <!-- ``<a href="https://arxiv.org/abs/2106.07999">ARTA: Collection and Classification of Ambiguous Requests and Thoughtful Actions</a>"<br> -->
                  ``<a href="https://aclanthology.org/2021.sigdial-1.9/">ARTA: Collection and Classification of Ambiguous Requests and Thoughtful Actions</a>"<br>
                  The 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pp. 77-88, Singapore (Online), July 2021<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://aclanthology.org/W19-4106/">Conversational Response Re-ranking Based on Event Causality and Role Factored Tensor Event Embedding</a>"<br>
                  The 1st Workshop NLP for Conversational AI ACL 2019 Workshop (ConvAI), pp. 51-59, Florence, Italy, August 2019, <font color="red"><b>Best Paper Award</b></font><br>
                </li>
              </ul>
            </li>

            <li>
              <b>Non-referred Conference Papers</b><br>
              <ul>
                <li>
                  <u>Shohei Tanaka</u>, Tosho Hirasawa, Yoshitaka Ushiku.<br>
                  ``<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q6-16.pdf">Investigation of Automatic Annotation with LLMs for Evidence-Based Review Generation</a>''<br>
                  The 31st Annual Conference of The Association for Natural Language Processing (ANLP), pp. 2562-2566, Nagasaki, Japan, March 2025, In Japanese<br>
                </li>
                <li>
                  Taiga Masuda, <u>Shohei Tanaka</u>, Tosho Hirasawa, Yoshitaka Ushiku.<br>
                  ``<a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q3-22.pdf">Paper2Poster: Generating Academic Posters Using LLMs</a>''<br>
                  The 31st Annual Conference of The Association for Natural Language Processing (ANLP), pp. 1297-1302, Nagasaki, Japan, March 2025, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Yoshitaka Ushiku.<br>
                  ``<a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/C7-2.pdf">A Dataset for Identifying Introduction Sentences and Body Paragraphs in Scientific Papers That Describe the Same Contribution</a>''<br>
                  The 30th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 1852-1857, Kobe, Japan, March 2024, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Konosuke Yamasaki, Akishige Yuguchi, Seiya Kawano, Satoshi Nakamura, Koichiro Yoshino.<br>
                  ``<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/H6-1.pdf">Reflective Action Selection of Dialogue Robot Integrating Ambiguous Requests and Observed Surrounding Situations</a>''<br>
                  The 29th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 1377-1382, Okinawa, Japan, March 2023, In Japanese<br>
                </li>
                <li>
                  Konosuke Yamasaki, <u>Shohei Tanaka</u>, Seiya Kawano, Akishige Yuguchi, Koichiro Yoshino.<br>
                  ``<a href="https://www.anlp.jp/proceedings/annual_meeting/2023/pdf_dir/Q12-3.pdf">Action Selection of Reflective Domestic Robot Based on Commonsense Inference</a>''<br>
                  <!-- 常識推論に基づく気の利いた家庭内ロボットの行動選択 -->
                  The 29th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 3105-3110, Okinawa, Japan, March 2023, In Japanese<br>
                </li>
                <li>
                  Konosuke Yamasaki, <u>Shohei Tanaka</u>, Seiya Kawano, Akishige Yuguchi, Koichiro Yoshino.<br>
                  ``<a href="">Towards Action Selection of Reflective Domestic Robot Based on Commonsense Inference</a>''<br>
                  <!-- 常識推論に基づく気の利いた家庭内ロボットの行動選択に向けて -->
                  The 96th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIGSLUD), Tokyo, Japan, December 2022, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Akishige Yuguchi, Seiya Kawano, Satoshi Nakamura, Koichiro Yoshino.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2022/202209_SIGNL_shohei-ta/202209_SIGNL_shohei-ta.paper.pdf">Dataset Collection of Ambiguous User Requests and Its Surrounding Situations for Developing Reflective Domestic Robot</a>''<br>
                  The 253rd Workshop of Special Interest Group on Natural Language (SIGNL), Kyoto (Online), Japan, September 2022, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2022/202203_ANLP_shohei-ta/202203_ANLP_shohei-ta.paper.pdf">Selecting Reflective System Action to Ambiguous User Requests Using Causality Knowledge</a>''<br>
                  The 28th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 1084-1089, Shizuoka (Online), Japan, March 2022, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2021/202103_ANLP_shohei-ta/202103_ANLP_shohei-ta.paper.pdf">Collection and Classification of A Dialogue Corpus Including Ambiguous Requests and Thoughtful Actions</a>''<br>
                  The 27th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 359-364, Fukuoka (Online), Japan, March 2021, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2020/202011_SIGSLUD_shohei-ta/202011_SIGSLUD_shohei-ta.paper.pdf">Collecting Corpus Including Smart Responses Focusing on Functions of Dialogue Agent</a>''<br>
                  The 90th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIGSLUD), Tokyo (Online), Japan, November 2020, <font color="red"><b>Young Sprout Award</b></font>, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2020/202003_ANLP_shohei-ta/202003_ANLP_shohei-ta.paper.pdf">Case Analysis for Conversational Response Re-ranking Based on Coherency of Sequential Events</a>''<br>
                  The 26th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 1316-1319, Ibaraki (Online), Japan, March 2020, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2019/201912_SIGSLUD_shohei-ta/201912_SIGSLUD_shohei-ta.paper.pdf">Conversational Response Selection Model Based on Event Coherency Estimation</a>''<br>
                  The 87th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIGSLUD), Tokyo, Japan, December 2019, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2019/201908_SIGNL_shohei-ta/201908_SIGNL_shohei-ta.paper.pdf">Analysis of Conversational Response Re-ranking Based on Event Causality and Role Factored Tensor Event Embedding</a>''<br>
                  The 241st Workshop of Special Interest Group on Natural Language (SIGNL), Hokkaido, Japan, August 2019, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2019/201903_ANLP_shohei-ta/201903_ANLP_shohei-ta.paper.pdf">Incorporating Event Causality to Re-ranking for Conversational Dialogue Responses and its Evaluation</a>"<br>
                  The 25th Annual Conference of The Association for Natural Language Processing (ANLP), pp. 1026-1029, Nagoya, Japan, March 2019, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  ``<a href="https://ahcweb01.naist.jp/papers/conference/2018/201811_SLUD_shohei-ta/201811_SLUD_shohei-ta.paper.pdf">Incorporating Event Causality to Re-ranking for Conversational Dialogue Responses</a>''<br>
                  The 84th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIGSLUD), Tokyo, Japan, November 2018, In Japanese<br>
                </li>
                <!-- <li>
                  <u>Shohei Tanaka</u>, Yusei Teramoto, Akinobu Lee.<br>
                  ``Easy Talk Suhama-Shoten"<br>
                  The 120th Workshop of Special Interest Group on Spoken Language Processing (SIGSLP), Ibaraki, Japan, February 2018, In Japanese
                </li> -->
              </ul>
            </li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Awards
            </span>
          </h2>
          <ul class="None">
            <li>Exemption from Scholarship Refund for Excellent Student, Japan Student Services Organization (JASSO) Type I Scholarship for Doctor Student, 4,392,000 JPY, 2023</li>
            <li>Accepted for Erasmus+ International Credit Mobility (ICM) Program, Study Abroad Support Fund, 3,145 EUR, 2022</li>
            <li>Young Sprout Award, The 90th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIGSLUD), 2020</li>
            <li>Exemption from Scholarship Refund for Excellent Student, Japan Student Services Organization (JASSO) Type I Scholarship for Master Student, 2,112,000 JPY, 2020</li>
            <li>Accepted for NAIST Top Scholarship Program, Nara Institute of Science and Technology, 2020</li>
            <li>Best Paper Award, The 1st Workshop NLP for Conversational AI ACL 2019 Workshop (ConvAI), 2019</li>
            <!-- <li>Scond Prize, Freestyle, App Development, NEXT COMMUNICATION AWARDS 2017 (Japanese Smartphone Application Contest), 2017</li> -->
          </ul>

          <!-- <h2 class="Body">
            <span class="Body">
              Skills
            </span>
          </h2>
          <ul class="None">
            <li>Python</li>
            <li>PyTorch</li>
            <li>C++</li>
            <li>Swift</li>
            <li>Arduino</li>
            <li>Raspberry Pi</li>
          </ul> -->

          <!-- <h2 class="Body">
            <span class="Body">
              Works
            </span>
          </h2>

          <h3 class="Body">
            <a href="https://vimeo.com/239294559">Easy Talk Suhama-Shoten（しゃべってらくらく 洲浜商店）, 2017</a>
          </h3>
          <img src="works/suhama.jpg" class="Work">
          <p class="Body">
            Suhama-Shoten is a spoken dialogue system to help elderly people with shopping.
            Users can order items by only talking with a character. 
            The system runs on a smartphone.
            <a href="https://www.slideshare.net/ShoheiTanaka2/ncf2017-86057166">Slides (in Japanese)</a><br>
            <!-- NCF2017 アプリ開発フリー部門で<a href="https://www.nttdocomo.co.jp/campaign_event/tokai/ncf_award/2017.html">準グランプリ</a>を獲得しました． -->
          <!-- </p> -->

          <!-- 
          <h3 class="Body">
            <a href="https://youtu.be/NlB1CZMd\_CM">Ama-no-Iwato Shiritori（天の岩戸しりとり）, 2016</a>
          </h3>
          <img src="works/iwato.jpg" class="Work">
          <p class="Body">
            <i>Ama-no-Iwato</i> is a story included in <i>Kojiki</i>, the Japanese oldest extant chronicle.
            <i>Shiritori</i> is a Japanese word game in which the players are required to say a word which begins with the final kana of the previous word.
            Users define a number and say words to make the character count equal to the defined number.
          </p>
          -->

          <!-- <h3 class="Body">
            <a href="https://youtu.be/7jeXsVbNgpM">Spoken Controlled Car, 2016</a>
          </h3>
          <img src="works/radicon.jpg" class="Work">
          <p class="Body">
            A spoken controlled toy car using a Raspberry Pi and LEGO.
            The commands are "foward," "back," "turn left," "turn right," and "come on."
            The system was exhibited at <a href="http://makezine.jp/event/makers2016/shouhei_tanaka/">Maker Faire Tokyo 2016</a>.
          </p>

          <h3 class="Body">
            <a href="https://youtu.be/aVoW5HBWl68">Sea Lion Puppet, 2016</a>
          </h3>
          <img src="works/Puppet.png" class="Work">
          <p class="Body">
            A sea lion puppet for children using an Arduino.<br>
            By an iPhone application, users can make the puppet take actions: nodding, shaking arms, and making a sound.
          </p>

          <h3 class="Body">
            <a href="https://youtu.be/NlB1CZMd_CM">Pinbo (Penguin Puppet), 2015</a>
          </h3>
          <img src="works/Pinbo.jpg" class="Work">
          <p class="Body">
            A penguin puppet using an Arduino.
            Reacting to sound and light, the puppet takes three actions: turning around, shaking hands, turning away.
          </p> -->

          <!-- 
          <h3 class="Body">
            <a href="https://www.amazon.co.jp/dp/B07C6115HJ/">声で買い物！シミュレーション (4/2018)</a>
          </h3>
          <img src="works/ShoppingSimulation.png" class="Work">
          <p class="Body">
            Amazon Alexa を使ってボイスユーザーインターフェース (VUI) で軽食デリバリーを頼む過程をシミュレーションできる（実際に買い物を行えるわけではない）Skill です．VUI による買い物をシミュレーションするだけの何の役にも立たない Skill ですが, ユーザを迷わせない対話フローの設計, 想定外のユーザ発話へのエラーハンドリングなど, 作る側が学べることは多かったかと思います．<br>
            ソースコードは <a href="https://github.com/shohei-ta-ds7/ShoppingSimulator">GitHub</a> 上に公開しています．
          </p>

          <h3 class="Body">Pun (4/2015)</h3>
          <img src="works/Pun.jpg" class="Work">
          <p class="Body">
            パスワード管理アプリケーションです．<br>
            Punには「語呂合わせ」という意味があり, その名の通りひらがなからの語呂合わせパスワード生成機能が特徴となっています．
          </p>

          <h3 class="Body">行列計算 (12/2014)</h3>
          <img src="works/MC.jpg" class="Work">
          <p class="Body">
            最初に作成したiOSアプリケーション．UIは友人に作成してもらいました．
          </p>
          <br>
          -->

          <!-- <h2 class="Body">
            <span class="Body">
              Links
            </span>
          </h2>
          <ul class="None">
            <li>
              <a href="https://ahcweb01.naist.jp/">
                AHC Lab
              </a>
            </li>
          </ul> -->
          <br>
        </fieldset>
      </div>
      <br>
    </body>
</html>
