<html>
    <head>
      <meta charset="UTF-8">
      <title>Shohei Tanaka</title>
      <link rel="stylesheet" type="text/css" href="style.css">
      <!-- <link rel="shortcut icon" type="image/vnd.microsoft.icon" href="./favicons/favicon.ico">
      <link rel="icon" type="image/vnd.microsoft.icon" href="./favicons/favicon.ico">
      <link rel="apple-touch-icon" sizes="57x57" href="./favicons/apple-touch-icon-57x57.png">
      <link rel="apple-touch-icon" sizes="60x60" href="./favicons/apple-touch-icon-60x60.png">
      <link rel="apple-touch-icon" sizes="72x72" href="./favicons/apple-touch-icon-72x72.png">
      <link rel="apple-touch-icon" sizes="76x76" href="./favicons/apple-touch-icon-76x76.png">
      <link rel="apple-touch-icon" sizes="114x114" href="./favicons/apple-touch-icon-114x114.png">
      <link rel="apple-touch-icon" sizes="120x120" href="./favicons/apple-touch-icon-120x120.png">
      <link rel="apple-touch-icon" sizes="144x144" href="./favicons/apple-touch-icon-144x144.png">
      <link rel="apple-touch-icon" sizes="152x152" href="./favicons/apple-touch-icon-152x152.png">
      <link rel="apple-touch-icon" sizes="180x180" href="./favicons/apple-touch-icon-180x180.png">
      <link rel="icon" type="image/png" sizes="192x192" href="./favicons/android-chrome-192x192.png">
      <link rel="icon" type="image/png" sizes="48x48" href="./favicons/favicon-48x48.png">
      <link rel="icon" type="image/png" sizes="96x96" href="./favicons/favicon-96x96.png">
      <link rel="icon" type="image/png" sizes="96x96" href="./favicons/favicon-160x160.png">
      <link rel="icon" type="image/png" sizes="96x96" href="./favicons/favicon-196x196.png">
      <link rel="icon" type="image/png" sizes="16x16" href="./favicons/favicon-16x16.png">
      <link rel="icon" type="image/png" sizes="32x32" href="./favicons/favicon-32x32.png">
      <link rel="manifest" href="./favicons/manifest.json"> -->
      <!-- <meta name="msapplication-TileColor" content="#2d88ef">
      <meta name="msapplication-TileImage" content="./favicons/mstile-144x144.png"> -->
    </head>
    <body>
      <!-- <div class="Header">
        <label style="color: #FFFFFF; margin-top: 10px; font-size: 40px;">Shohei TANAKA</label>
      </div> -->

      <br>
      <br>

      <div class="Body">
        <fieldset class="Body">
          <h1 style="padding: 5px;">
            <span class="Body">
              Shohei Tanaka/田中 翔平/たなか しょうへい
            </span>
          </h1>
          <img src="profile.jpg" class="Work">
          <p class="Body">
            AHC Lab, NAIST, Japan<br>
            E-mail: tanaka.shohei.tj7 at is.naist.jp
          </p>

          <h2 class="Body">
            <span class="Body">
              Profile
            </span>
          </h2>
          <p class="Body">
            I am a Ph.D. student at Augmented Human Communication Lab (AHC), Nara Institute of Science and Technology (NAIST).
            Since I was an undergraduate student, I have been strongly interested in systems that interact with users.
            During my undergraduate, I made some products to pursue my interest.
            I have been studying dialogue systems in my graduate school.
            My current research interest is reflective dialogue agents that respond with reflective actions to ambiguous user requests.
            The agents assume to be used in tasks that users sometimes can not clearly verbalize their requests such as sightseeing navigation or hotel reception.
            I also interested in how dialogue systems use external knowledge such as event causality.
            I have been studying these topics to develop a dialogue agent that can support users in diverse situations as well as reflective human concierges.
          </p>

          <h2 class="Body">
            <span class="Body">
              Work Experience
            </span>
          </h2>
          <ul class="None">
            <li>
              <b>Research Assistant</b><br>
              <ul>
                <li>Guardian Robot Project (GRP), R-IH, RIKEN, April 2021 -- Present</li>
                <li>Center for Advanced Intelligence Project (AIP), RIKEN, July 2020 -- March 2021</li>
                <li>Nara Institute of Science and Technology, June 2019 -- Present</li>
                <li>PRESTO, Japan Science and Technology Agency, April 2019 -- June 2020</li>
                <li>National Institute of Information and Communications Technology (NICT), November 2018 -- March 2019</li>
              </ul>
            </li>
            <!-- <li>
              <b>Others</b><br>
              <ul>
              </ul>
            </li> -->
            <li>
              <b>Internships</b><br>
              <ul>
                <li>Fixstars Inc., February 2018 -- March 2018</li>
                <li>Nissan Motor Co., Ltd., August 2016 -- September 2016</li>
              </ul>
            </li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Education
            </span>
          </h2>
          <ul class="None">
            <li>
              <b>Master of Engineering, Nara Institute of Science and Technology, Nara, Japan, 2020</b><br>
              <b>Thesis:</b> Conversational Response Re-ranking Based on Coherency of Sequential Events<br>
              <b>Supervisor:</b> <a href="https://ahcweb01.naist.jp/Prof.Nakamura/index_e.html">Prof. Satoshi Nakamura</a>
            </li>
            <li>
              <b>Bachelor of Engineering, Nagoya Institute of Technology, Nagoya, Japan, 2018</b><br>
              <b>Thesis:</b> A Design Methodology of Real-World Universal Voice Interface and its Model Case: "Easy Talk Suhama-Shoten"<br>
              <b>Supervisor:</b> <a href="https://www.slp.nitech.ac.jp/en/members/ri/">Prof. Akinobu Lee</a>
            </li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Publications
            </span>
          </h2>
          <ul class="None">
            <li>
              <b>Journal Papers</b><br>
              <ul>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  <!-- "<a href="https://ahcweb01.naist.jp/papers/journal/2021/202103_TNLP_shohei-ta/202103_TNLP_shohei-ta.paper.pdf">Relationships Between Coherency of Sequential Events and Dialogue Continuity on Conversational Response</a>"<br> -->
                  "<a href="https://www.jstage.jst.go.jp/article/jnlp/28/1/28_26/_article/-char/ja/">Relationships Between Coherency of Sequential Events and Dialogue Continuity on Conversational Response"</a><br>
                  Transaction of Natural Language Processing (TNLP), Vol.28, No.1, pp. 26-59, March 2021, In Japanese<br>
                </li>
              </ul>
            </li>

            <li>
              <b>International Conference Papers</b><br>
              <ul>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  <!-- "<a href="https://arxiv.org/abs/2106.07999">ARTA: Collection and Classification of Ambiguous Requests and Thoughtful Actions</a>"<br> -->
                  
                  "<a href="https://aclanthology.org/2021.sigdial-1.9/">ARTA: Collection and Classification of Ambiguous Requests and Thoughtful Actions</a>"<br>
                  The 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL), pp. 77-88, Singapore, July 2021<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://www.aclweb.org/anthology/W19-4106/">Conversational Response Re-ranking Based on Event Causality and Role Factored Tensor Event Embedding</a>"<br>
                  The 1st Workshop NLP for Conversational AI ACL 2019 Workshop (ConvAI), pp. 51-59, Florence, Italy, August 2019, Oral &amp; Poster, <font color="red"><b>Best Paper Award</b></font><br>
                </li>
              </ul>
            </li>

            <li>
              <b>Domestic Conference Papers</b><br>
              <ul>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2021/202103_ANLP_shohei-ta/202103_ANLP_shohei-ta.paper.pdf">Collection and Classification of A Dialogue Corpus Including Ambiguous Requests and Thoughtful Actions</a>”<br>
                  The 27th Annual Conference of The Association for Natural Language Processing (ANLP), Fukuoka (Online), pp. 359-364, Japan, March 2021, Poster, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2020/202011_SIGSLUD_shohei-ta/202011_SIGSLUD_shohei-ta.paper.pdf">Collecting Corpus Including Smart Responses Focusing on Functions of Dialogue Agent</a>”<br>
                  The 90th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIG-SLUD), Online, Japan, November 2020, Poster, <font color="red"><b>Young Sprout Award</b></font>, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2020/202003_ANLP_shohei-ta/202003_ANLP_shohei-ta.paper.pdf">Case Analysis for Conversational Response Re-ranking Based on Coherency of Sequential Events</a>”<br>
                  The 26th Annual Conference of The Association for Natural Language Processing (ANLP), Ibaraki (Online), pp. 1316-1319, Japan, March 2020, Poster, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2019/201912_SIGSLUD_shohei-ta/201912_SIGSLUD_shohei-ta.paper.pdf">Conversational Response Selection Model Based on Event Coherency Estimation</a>”<br>
                  The 87th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIG-SLUD), Tokyo, Japan, December 2019, Poster, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2019/201908_SIGNL_shohei-ta/201908_SIGNL_shohei-ta.paper.pdf">Analysis of Conversational Response Re-ranking Based on Event Causality and Role Factored Tensor Event Embedding</a>”<br>
                  The 241st Workshop of Special Interest Group on Natural Language (SIG-NL), Hokkaido, Japan, August 2019, Oral, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2019/201903_ANLP_shohei-ta/201903_ANLP_shohei-ta.paper.pdf">Incorporating Event Causality to Re-ranking for Conversational Dialogue Responses and its Evaluation</a>"<br>
                  The 25th Annual Conference of The Association for Natural Language Processing (ANLP), Nagoya, pp. 1026-1029, Japan, March 2019, Oral, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Koichiro Yoshino, Katsuhito Sudoh, Satoshi Nakamura.<br>
                  "<a href="https://ahcweb01.naist.jp/papers/conference/2018/201811_SLUD_shohei-ta/201811_SLUD_shohei-ta.paper.pdf">Incorporating Event Causality to Re-ranking for Conversational Dialogue Responses</a>”<br>
                  The 84th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIG-SLUD), Tokyo, Japan, November 2018, Poster, In Japanese<br>
                </li>
                <li>
                  <u>Shohei Tanaka</u>, Yusei Teramoto, Akinobu Lee.<br>
                  "Easy Talk Suhama-Shoten"<br>
                  The 120th Workshop of Special Interest Group on Spoken Language Processing (SIG-SLP), Ibaraki, Japan, February 2018, Poster, In Japanese
                </li>
              </ul>
            </li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Awards
            </span>
          </h2>
          <ul class="None">
            <li>Offer of Exemption from Scholarship Refund for Excellent Student, Japan Student Services Organization (JASSO) Type I Scholarship for Doctor Student, 2021</li>
            <li>Young Sprout Award, The 90th Workshop of Special Interest Group on Spoken Language Understanding and Dialogue Processing (SIG-SLUD), 2020</li>
            <li>Exemption from Scholarship Refund for Excellent Student, Japan Student Services Organization (JASSO) Type I Scholarship for Master Student (2,112,000 JPY), 2020</li>
            <li>Accept of NAIST Top Scholarship Program, Nara Institue of Science and Technology, 2020</li>
            <li>Best Paper Award, The 1st Workshop NLP for Conversational AI ACL 2019 Workshop (ConvAI), 2019</li>
            <li>Scond Prize, Freestyle, App Development, NEXT COMMUNICATION AWARDS 2017 (Japanese Smartphone Application Contest), 2017</li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Skills
            </span>
          </h2>
          <ul class="None">
            <li>Python</li>
            <li>PyTorch</li>
            <li>C++</li>
            <li>Swift</li>
            <li>Arduino</li>
            <li>Raspberry Pi</li>
          </ul>

          <h2 class="Body">
            <span class="Body">
              Works
            </span>
          </h2>

          <h3 class="Body">
            <a href="https://vimeo.com/239294559">Easy Talk Suhama-Shoten（しゃべってらくらく 洲浜商店）, 2017</a>
          </h3>
          <img src="works/suhama.jpg" class="Work">
          <p class="Body">
            Suhama-Shoten is a spoken dialogue system to help elderly people with shopping.
            Users can order items by only talking with a character. 
            The system runs on a smartphone.
            <a href="https://www.slideshare.net/ShoheiTanaka2/ncf2017-86057166">Slides (in Japanese)</a><br>
            <!-- NCF2017 アプリ開発フリー部門で<a href="https://www.nttdocomo.co.jp/campaign_event/tokai/ncf_award/2017.html">準グランプリ</a>を獲得しました． -->
          </p>

          <!-- 
          <h3 class="Body">
            <a href="https://youtu.be/NlB1CZMd\_CM">Ama-no-Iwato Shiritori（天の岩戸しりとり）, 2016</a>
          </h3>
          <img src="works/iwato.jpg" class="Work">
          <p class="Body">
            <i>Ama-no-Iwato</i> is a story included in <i>Kojiki</i>, the Japanese oldest extant chronicle.
            <i>Shiritori</i> is a Japanese word game in which the players are required to say a word which begins with the final kana of the previous word.
            Users define a number and say words to make the character count equal to the defined number.
          </p>
          -->

          <h3 class="Body">
            <a href="https://youtu.be/7jeXsVbNgpM">Spoken Controlled Car, 2016</a>
          </h3>
          <img src="works/radicon.jpg" class="Work">
          <p class="Body">
            A spoken controlled toy car using a Raspberry Pi and LEGO.
            The commands are "foward," "back," "turn left," "turn right," and "come on."
            The system was exhibited at <a href="http://makezine.jp/event/makers2016/shouhei_tanaka/">Maker Faire Tokyo 2016</a>.
          </p>

          <h3 class="Body">
            <a href="https://youtu.be/aVoW5HBWl68">Sea Lion Puppet, 2016</a>
          </h3>
          <img src="works/Puppet.png" class="Work">
          <p class="Body">
            A sea lion puppet for children using an Arduino.<br>
            By an iPhone application, users can make the puppet take actions: nodding, shaking arms, and making a sound.
          </p>

          <h3 class="Body">
            <a href="https://youtu.be/NlB1CZMd_CM">Pinbo (Penguin Puppet), 2015</a>
          </h3>
          <img src="works/Pinbo.jpg" class="Work">
          <p class="Body">
            A penguin puppet using an Arduino.
            Reacting to sound and light, the puppet takes three actions: turning around, shaking hands, turning away.
          </p>

          <!-- 
          <h3 class="Body">
            <a href="https://www.amazon.co.jp/dp/B07C6115HJ/">声で買い物！シミュレーション (4/2018)</a>
          </h3>
          <img src="works/ShoppingSimulation.png" class="Work">
          <p class="Body">
            Amazon Alexa を使ってボイスユーザーインターフェース (VUI) で軽食デリバリーを頼む過程をシミュレーションできる（実際に買い物を行えるわけではない）Skill です．VUI による買い物をシミュレーションするだけの何の役にも立たない Skill ですが, ユーザを迷わせない対話フローの設計, 想定外のユーザ発話へのエラーハンドリングなど, 作る側が学べることは多かったかと思います．<br>
            ソースコードは <a href="https://github.com/shohei-ta-ds7/ShoppingSimulator">GitHub</a> 上に公開しています．
          </p>

          <h3 class="Body">Pun (4/2015)</h3>
          <img src="works/Pun.jpg" class="Work">
          <p class="Body">
            パスワード管理アプリケーションです．<br>
            Punには「語呂合わせ」という意味があり, その名の通りひらがなからの語呂合わせパスワード生成機能が特徴となっています．
          </p>

          <h3 class="Body">行列計算 (12/2014)</h3>
          <img src="works/MC.jpg" class="Work">
          <p class="Body">
            最初に作成したiOSアプリケーション．UIは友人に作成してもらいました．
          </p>
          <br>
          -->

          <h2 class="Body">
            <span class="Body">
              Links
            </span>
          </h2>
          <ul class="None">
            <li>
              <a href="https://ahcweb01.naist.jp/">
                AHC Lab
              </a>
            </li>
            <!-- <li>
              <a href="https://twitter.com/shohei-ta-ds7">
                Twitter
              </a>
            </li> -->
            <!-- <li>
              <a href="https://www.facebook.com/profile.php?id=100008325450945">
                Facebook
              </a>
            </li> -->
            <li>
              <a href="https://github.com/shohei-ta-ds7">
                GitHub
              </a>
            </li>
            <!-- <li>
              <a href="https://qiita.com/shohei-ta-ds7">
                Qiita
              </a>
            </li> -->
            <!-- <li>
              <a href="https://ja.overleaf.com/read/rqkpffywbtmy">
                CV
              </a>
            </li> -->
          </ul>
          <br>
        </fieldset>
      </div>
      <br>
    </body>
</html>
